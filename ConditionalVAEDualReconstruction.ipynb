{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional VAE\n",
    "\n",
    "With Input:\n",
    "- Image Label\n",
    "- Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "#import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "#import model\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveVisionDataset (Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file, index_col=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if type(index) == torch.Tensor:\n",
    "            index = index.item()\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        #image = image/(image.max()/255.0)\n",
    "        shape_label = torch.tensor(int(self.annotations.iloc[index,1]))\n",
    "        #print(shape_label)\n",
    "        cam_loc = torch.tensor(ast.literal_eval(self.annotations.iloc[index,2]))\n",
    "#         print(cam_loc)\n",
    "        cam_loc = torch.tensor([cam_loc[1], cam_loc[2]])\n",
    "#         print(cam_loc)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, shape_label, cam_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "\n",
    "        self.img_lin1 = nn.Linear(init_filters*(conv_out_size**2), 1024)\n",
    "        self.img_lin2 = nn.Linear(4096, 1024)\n",
    "        \n",
    "        self.coord_lin1 = nn.Linear(2,16)\n",
    "        \n",
    "        self.comb_lin1 = nn.Linear(1024+16+6,256)\n",
    "\n",
    "        self.mu = nn.Linear(256, z_dim)\n",
    "        self.sigma = nn.Linear(256, z_dim)\n",
    "        \n",
    "    def forward(self, image, label, coord):\n",
    "        \n",
    "        #Image\n",
    "        x = self.conv1(image)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #print(\"before flatten:\" + str(x.shape))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"after flatten:\" + str(x.shape))\n",
    "\n",
    "        x = self.img_lin1(x)\n",
    "        x = F.relu(x)   \n",
    "\n",
    "        #Coordinate\n",
    "        coord = self.coord_lin1(coord)\n",
    "        \n",
    "        #Label\n",
    "        label = F.one_hot(label, num_classes=6)\n",
    "        label = label.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        #Concatenation\n",
    "        concat = torch.cat([x, label, coord],dim=1)\n",
    "        \n",
    "        x = self.comb_lin1(concat)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # get `mu` and `log_var`\n",
    "        mu = self.mu(x)\n",
    "        log_var = self.sigma(x)\n",
    "        \n",
    "        return mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.comb_lin1 = nn.Linear(z_dim+6, 1024)\n",
    "        self.comb_lin2 = nn.Linear(1024, init_filters*(conv_out_size**2))\n",
    "        \n",
    "        self.coord_lin1 = nn.Linear(z_dim+6, 2)\n",
    "        \n",
    "        self.dec1 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec2 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec3 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec4 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec5 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=3, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, label, coord):\n",
    "        \n",
    "        #Label\n",
    "        label = F.one_hot(label, num_classes=6)\n",
    "        label = label.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        #Concatenation\n",
    "        concat = torch.cat([x,label],dim=1)\n",
    "        \n",
    "        #Coordinate Recontruction\n",
    "        coordinate_reconstruction = self.coord_lin1(concat)\n",
    "        \n",
    "        #Image Reconstruction\n",
    "        x = self.comb_lin1(concat)\n",
    "        x = F.relu(x)\n",
    "        x = self.comb_lin2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x=x.view(-1, init_filters, conv_out_size, conv_out_size)\n",
    "        #print(\"after unflatten:\")\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.dec1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec5(x)\n",
    "        image_reconstruction = torch.sigmoid(x)\n",
    "        \n",
    "        return image_reconstruction, coordinate_reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.decoder = Decoder(z_dim)\n",
    "    \n",
    "    def forward(self, image, label, coord):\n",
    "        mu, log_var = self.encoder(image, label, coord)\n",
    "        \n",
    "        #print('mu: ', mu.shape)\n",
    "        #print('log_var: ', log_var.shape)\n",
    "        \n",
    "        #sample z from latent distribution q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu,std)\n",
    "        z = q.rsample()\n",
    "        #print('z shape: ', z.shape)\n",
    "        \n",
    "        img_recon, coord_recon = self.decoder(z, label, coord)\n",
    "                \n",
    "        return img_recon, coord_recon, mu, log_var, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_likelihood(mean, logscale, sample):\n",
    "    scale = torch.exp(logscale)\n",
    "    dist = torch.distributions.Normal(mean, scale)\n",
    "    log_pxz = dist.log_prob(sample)\n",
    "    return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "def kl_divergence(z, mu, std):\n",
    "    # --------------------------\n",
    "    # Monte carlo KL divergence\n",
    "    # --------------------------\n",
    "    # 1. define the first two probabilities (in this case Normal for both)\n",
    "    p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "    q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "    # 2. get the probabilities from the equation\n",
    "    log_qzx = q.log_prob(z)\n",
    "    log_pz = p.log_prob(z)\n",
    "\n",
    "    # kl\n",
    "    kl = (log_qzx - log_pz)\n",
    "    kl = kl.sum(-1)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        image, label, coord = batch\n",
    "        #print(image.size())\n",
    "        #print(label)\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            coord = coord.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        img_recon, coord_recon, mu, log_var, z = model(image, label, coord)\n",
    "        \n",
    "        img_recon_loss = loss(img_recon, image)\n",
    "        \n",
    "        coord_recon_loss = loss(coord_recon, coord)\n",
    "        \n",
    "#         print( str(img_recon_loss.item()) + \" \" + str(coord_recon_loss.item()) )\n",
    "        \n",
    "        recon_loss = img_recon_loss + coord_recon_loss\n",
    "        \n",
    "        std = torch.exp(log_var / 2)\n",
    "        kl = kl_divergence(z, mu, std)\n",
    "\n",
    "        elbo = (beta*kl + recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "        \n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += elbo\n",
    "    \n",
    "    train_loss = running_loss/len(dataloader.dataset) #Investigate\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, epoch):\n",
    "    model.eval()\n",
    "    running_loss_true = 0.0\n",
    "    running_loss_noisy = 0.0\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            \n",
    "            image, label, coord = batch\n",
    "            \n",
    "            noisy_z = (torch.FloatTensor(batch_size, 3, image_size, image_size).uniform_())*256\n",
    "            noisy_z = torch.round(noisy_z)\n",
    "                \n",
    "            if torch.cuda.is_available():\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                coord = coord.to(device)\n",
    "                noisy_z = noisy_z.to(device)\n",
    "            \n",
    "            img_recon, coord_recon, mu, log_var, z = model(image, label, coord)\n",
    "            \n",
    "            #print(\"Real Vector:\" + str(z.shape))\n",
    "            #print(\"Imitation Vector:\" + str(noisy_z.shape))\n",
    "            \n",
    "            img_recon_noise, coord_recon_noise, _, _, _  = model(noisy_z, label, coord)\n",
    "            \n",
    "            if (i == int(len(val_data)/dataloader.batch_size) - 1 and ( ((epoch%val_img_out_freq))==4) ): # or epoch > 90\n",
    "                num_rows = 4\n",
    "                both = torch.cat((image.view(batch_size, 3, image_size, image_size)[:4], \n",
    "                                  img_recon.view(batch_size, 3, image_size, image_size)[:4],\n",
    "                                  img_recon_noise.view(batch_size, 3, image_size, image_size)[:4]))\n",
    "                save_image(both.cpu(), f\"outputs/{parameter}{value}/imgs/output{epoch}.png\", nrow=num_rows)\n",
    "            \n",
    "#             recon_loss = gaussian_likelihood(reconstruction, log_scale, image)\n",
    "            recon_loss_true = loss(img_recon, image)\n",
    "            recon_loss_noisy = loss(img_recon_noise, image)\n",
    "        \n",
    "            std = torch.exp(log_var / 2)\n",
    "            kl = kl_divergence(z, mu, std)\n",
    "            \n",
    "#             print(\"Validation:\")\n",
    "#             print(\"kl:\" + str(kl))\n",
    "#             print(\"recon:\"+ str(recon_loss))\n",
    "\n",
    "            elbo_true = (beta*kl + recon_loss_true)\n",
    "            elbo_true = elbo_true.mean()\n",
    "        \n",
    "            elbo_noisy = (beta*kl + recon_loss_noisy)\n",
    "            elbo_noisy = elbo_noisy.mean()\n",
    "            \n",
    "            running_loss_true += elbo_true\n",
    "            \n",
    "            running_loss_noisy += elbo_noisy\n",
    "            \n",
    "            i+=1\n",
    "    \n",
    "    val_loss_true = running_loss_true/len(dataloader.dataset)\n",
    "    val_loss_noisy = running_loss_noisy/len(dataloader.dataset)\n",
    "    return val_loss_true, val_loss_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_vectors(model, dataloader):\n",
    "    model.eval()\n",
    "    latent = []\n",
    "    target = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            image, label, coord = batch\n",
    "            #if torch.cuda.is_available():\n",
    "            #    data = data.to(device)\n",
    "            mu, logvar = model.encoder(image.cuda(), label.cuda(), coord.cuda())\n",
    "            latent.extend(mu.cpu().detach().numpy())\n",
    "            target.extend(label.numpy())\n",
    "#         print(len(latent))\n",
    "#         print(latent)\n",
    "#         print(len(target))\n",
    "#         print(target)\n",
    "        return latent, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    drop = 0.5\n",
    "    epochs_drop = 25.0\n",
    "    lrate = initial_learning_rate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "def run_each():\n",
    "    train_loss = []\n",
    "    val_loss_true = []\n",
    "    val_loss_noisy = []\n",
    "    for epoch in range(epochs):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "        sleep(0.2)\n",
    "        \n",
    "        learning_rate = step_decay(epoch)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        train_epoch_loss = fit(model, train_loader)\n",
    "        \n",
    "        val_epoch_loss_true, val_epoch_loss_noisy = validate(model, val_loader, epoch)\n",
    "\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        val_loss_true.append(val_epoch_loss_true)\n",
    "        val_loss_noisy.append(val_epoch_loss_noisy)\n",
    "\n",
    "#         print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "#         print(f\"Val Loss: {val_epoch_loss:.4f}\")\n",
    "    return train_loss, val_loss_true, val_loss_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def runall():\n",
    "    train_loss, val_loss_true, val_loss_noisy = run_each()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(range(1,epochs+1), train_loss, label=\"Train Loss\")\n",
    "    plt.plot(range(1,epochs+1), val_loss_true, label=\"Validation Loss (True Reconstruction)\")\n",
    "    plt.plot(range(1,epochs+1), val_loss_noisy, label=\"Validation Loss (Noisy Reconstruction)\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    axes = plt.gca()\n",
    "    \n",
    "    latent, target = generate_latent_vectors(model, val_loader)\n",
    "    \n",
    "    with open('outputs/'+parameter+value+'/sample_latent_vectors'+parameter+value+'.csv','w', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([\"Latent\", \"Target\"])\n",
    "        \n",
    "        for i in range (0,len(latent)):\n",
    "            latent[i] = list(latent[i])\n",
    "            \n",
    "        wr.writerows(zip(latent, target))\n",
    "    \n",
    "    filepath = os.path.join(os.getcwd(), \"outputs\", parameter+str(value), parameter+str(value)+\".pth\")\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    \n",
    "    plt.savefig('outputs/'+parameter+value+'/loss'+parameter+value+'.png')\n",
    "    \n",
    "    with open('outputs/'+parameter+value+'/loss'+parameter+value+'.csv','w', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([\"Train loss\", \"Val loss\"])\n",
    "        \n",
    "        for i in range (0,len(train_loss)):\n",
    "            train_loss[i] = train_loss[i].item()\n",
    "        \n",
    "        for i in range (0,len(val_loss_true)):\n",
    "            val_loss_true[i] = val_loss_true[i].item()\n",
    "        \n",
    "        for i in range (0,len(val_loss_noisy)):\n",
    "            val_loss_noisy[i] = val_loss_noisy[i].item()\n",
    "            \n",
    "        wr.writerows(zip(train_loss, val_loss_true, val_loss_noisy))\n",
    "        \n",
    "    with open('outputs/lossCompare.csv', 'a+', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([parameter,\n",
    "                     value,\n",
    "                     train_loss[-1],\n",
    "                     val_loss_true[-1],\n",
    "                     val_loss_noisy[-1],\n",
    "                     enc_out_dim, \n",
    "                     latent_dim, \n",
    "                     epochs,\n",
    "                     batch_size, \n",
    "                     initial_learning_rate, \n",
    "                     kernel_size, \n",
    "                     stride,\n",
    "                     padding, \n",
    "                     init_filters,\n",
    "                     dropout_pcent,\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "param_dict = {\n",
    "    \n",
    "    \"enc_out_dim\": 512,\n",
    "    \"latent_dim\": 128,\n",
    "    \"conv_out_size\": 4,\n",
    "    \n",
    "    \"epochs\" : 250,\n",
    "    \"batch_size\" : 8,\n",
    "    \"initial_learning_rate\" : 0.001,\n",
    "    \n",
    "    \"kernel_size\" : 5,\n",
    "    \"stride\" : 2,\n",
    "    \"padding\" : 2,\n",
    "    \n",
    "    \"init_filters\" : 128,\n",
    "    \n",
    "    \"dropout_pcent\": 0.0,\n",
    "    \"image_size\": 128,\n",
    "    \n",
    "    \"label_dropout_pcent\": 0.0\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 188/188 [00:05<00:00, 36.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:01<00:00, 41.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 106.38it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_img_out_freq = 5\n",
    "parameter_list = ['DualReconstructionSingleConditional']\n",
    "value_list = [0]\n",
    "\n",
    "for parameter in parameter_list:\n",
    "    for value in value_list:\n",
    "        #Update the values to be updated and rerun the experiment\n",
    "        enc_out_dim = param_dict[\"enc_out_dim\"]\n",
    "        latent_dim = param_dict[\"latent_dim\"]\n",
    "        conv_out_size = param_dict[\"conv_out_size\"]\n",
    "\n",
    "        epochs = param_dict[\"epochs\"]\n",
    "        batch_size = param_dict[\"batch_size\"]\n",
    "        initial_learning_rate = param_dict[\"initial_learning_rate\"]\n",
    "\n",
    "        kernel_size = param_dict[\"kernel_size\"]\n",
    "        stride = param_dict[\"stride\"]\n",
    "        padding = param_dict[\"padding\"]\n",
    "        init_filters = param_dict[\"init_filters\"]\n",
    "        \n",
    "        dropout_pcent = param_dict[\"dropout_pcent\"]\n",
    "        image_size = param_dict[\"image_size\"]\n",
    "        \n",
    "        label_dropout_pcent = param_dict[\"label_dropout_pcent\"]\n",
    "        \n",
    "        beta = 1\n",
    "        \n",
    "        #Move batch_size to before so its trained on the same split?\n",
    "        set_used = 'datasets/SmallGrey'\n",
    "        train_data = ActiveVisionDataset(csv_file=set_used+'/TrainSet/rgbCSV.csv', root_dir=set_used+'/TrainSet/segImg/', transform = torchvision.transforms.ToTensor())\n",
    "        val_data = ActiveVisionDataset(csv_file=set_used+'/ValSet/rgbCSV.csv', root_dir= set_used+'/ValSet/segImg/', transform = torchvision.transforms.ToTensor())\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        img_size = len(train_data[0][0][0])\n",
    "        model = ConditionalVAE(latent_dim).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=initial_learning_rate)\n",
    "\n",
    "        log_scale = nn.Parameter(torch.Tensor([0.0])).to(device)\n",
    "        loss = nn.MSELoss(reduction = 'sum')\n",
    "        \n",
    "        \n",
    "        #Change the value to a string for later\n",
    "        value = str(value)\n",
    "        os.makedirs(\"outputs/\"+parameter+str(value), exist_ok=True)\n",
    "        os.makedirs(\"outputs/\"+parameter+str(value)+\"/imgs\", exist_ok=True)\n",
    "        \n",
    "        #Run the Test\n",
    "        runall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional VAE\n",
    "\n",
    "With Input:\n",
    "- Image Label\n",
    "- Coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "#import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "torch.cuda.empty_cache() \n",
    "#import model\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveVisionDataset (Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file, index_col=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if type(index) == torch.Tensor:\n",
    "            index = index.item()\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        #image = image/(image.max()/255.0)\n",
    "        shape_label = torch.tensor(int(self.annotations.iloc[index,1]))\n",
    "        #print(shape_label)\n",
    "        cam_loc = torch.tensor(ast.literal_eval(self.annotations.iloc[index,2]))\n",
    "        #print(cam_loc)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, shape_label, cam_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding\n",
    "        )\n",
    "\n",
    "        self.img_lin1 = nn.Linear(init_filters*(conv_out_size**2), 1024)\n",
    "        self.img_lin2 = nn.Linear(4096, 1024)\n",
    "        \n",
    "        self.label_lin1 = nn.Linear(6,16)\n",
    "        \n",
    "        self.coord_lin1 = nn.Linear(3,16)\n",
    "        \n",
    "        self.comb_lin1 = nn.Linear(1024+3+6,256)\n",
    "        self.comb_lin2 = nn.Linear(512,256)\n",
    "\n",
    "        self.mu = nn.Linear(256, z_dim)\n",
    "        self.sigma = nn.Linear(256, z_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_pcent)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(1024+3+6)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "    def forward(self, image, label, coord):\n",
    "        \n",
    "        #Image                                                                 #print(\"before anything\") #print(image.shape)\n",
    "        x = self.conv1(image)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #print(\"before flatten:\" + str(x.shape))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"after flatten:\" + str(x.shape))\n",
    "\n",
    "        x = self.img_lin1(x)\n",
    "        x = F.relu(x)\n",
    "#         x = self.img_lin2(x)\n",
    "#         x = F.relu(x)\n",
    "        \n",
    "        #Label                                                  #label = torch.unsqueeze(label, dim=1)\n",
    "        label = F.one_hot(label, num_classes=6)\n",
    "        label = label.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        y = label\n",
    "#         y = self.label_lin1(label)\n",
    "#         y = F.relu(y)\n",
    "        \n",
    "        #Coordinate\n",
    "        z = coord\n",
    "#         z = self.coord_lin1(coord)\n",
    "#         z = F.relu(z)\n",
    "        \n",
    "        #Concatenation\n",
    "        concat = torch.cat([x,y,z],dim=1)\n",
    "        #x = torch.cat([x,y],dim=1)\n",
    "                                                                               #print(label) print(label.shape) print(coord) \n",
    "                                                                 #print(coord.shape) print(y) print(y.shape) #print(x.shape)\n",
    "        \n",
    "#         x = self.dropout(concat) if reintroduced change line below to x\n",
    "        #print(\"after combination:\" + str(x.shape))\n",
    "#         x = self.bn1(concat)\n",
    "#         x = self.dropout(concat)\n",
    "        x = self.comb_lin1(concat)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # get `mu` and `log_var`\n",
    "        mu = self.mu(x)\n",
    "        log_var = self.sigma(x)\n",
    "        \n",
    "        return mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.img_lin1 = nn.Linear(z_dim, 256)\n",
    "        \n",
    "        self.label_lin1 = nn.Linear(6,16)\n",
    "        \n",
    "        self.coord_lin1 = nn.Linear(3,16)\n",
    "        \n",
    "        self.comb_lin1 = nn.Linear(256+3+6, 1024)\n",
    "        self.comb_lin2 = nn.Linear(1024, init_filters*(conv_out_size**2))\n",
    "        \n",
    "        \n",
    "        self.dec1 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec2 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec3 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec4 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=init_filters, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        self.dec5 = nn.ConvTranspose2d(\n",
    "            in_channels=init_filters, out_channels=3, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=1\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_pcent)\n",
    "        \n",
    "    def forward(self, z, label, coord):\n",
    "        \n",
    "        #Latent Vector\n",
    "        x = self.img_lin1(z)\n",
    "        \n",
    "        #Label\n",
    "        label = F.one_hot(label, num_classes=6)\n",
    "        label = label.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        y = label\n",
    "#         y = self.label_lin1(label)\n",
    "#         y = F.relu(y)\n",
    "        \n",
    "        #Coordinate\n",
    "        z = coord        \n",
    "#         z = self.coord_lin1(coord)\n",
    "#         z = F.relu(z)\n",
    "        \n",
    "        #Concatenation\n",
    "        concat = torch.cat([x,y,z],dim=1)\n",
    "        #x = torch.cat([x,y],dim=1)\n",
    "        \n",
    "#         x = self.dropout(concat) if reintroduced change line below to x\n",
    "#         x = self.dropout(concat)\n",
    "        x = self.comb_lin1(concat)\n",
    "        x=F.relu(x)\n",
    "        x = self.comb_lin2(x)\n",
    "        x=F.relu(x)\n",
    "        \n",
    "        x=x.view(-1, init_filters, conv_out_size, conv_out_size)\n",
    "        #print(\"after unflatten:\")\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.dec1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dec5(x)\n",
    "        reconstruction = torch.sigmoid(x)\n",
    "        \n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.decoder = Decoder(z_dim)\n",
    "    \n",
    "    def forward(self, image, label, coord):\n",
    "        mu, log_var = self.encoder(image, label, coord)\n",
    "        \n",
    "        #print('mu: ', mu.shape)\n",
    "        #print('log_var: ', log_var.shape)\n",
    "        \n",
    "        #sample z from latent distribution q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu,std)\n",
    "        z = q.rsample()\n",
    "        #print('z shape: ', z.shape)\n",
    "        \n",
    "        reconstruction = self.decoder(z, label, coord)\n",
    "                \n",
    "        return reconstruction, mu, log_var, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_likelihood(mean, logscale, sample):\n",
    "    scale = torch.exp(logscale)\n",
    "    dist = torch.distributions.Normal(mean, scale)\n",
    "    log_pxz = dist.log_prob(sample)\n",
    "    return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "def kl_divergence(z, mu, std):\n",
    "    # --------------------------\n",
    "    # Monte carlo KL divergence\n",
    "    # --------------------------\n",
    "    # 1. define the first two probabilities (in this case Normal for both)\n",
    "    p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "    q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "    # 2. get the probabilities from the equation\n",
    "    log_qzx = q.log_prob(z)\n",
    "    log_pz = p.log_prob(z)\n",
    "\n",
    "    # kl\n",
    "    kl = (log_qzx - log_pz)\n",
    "    kl = kl.sum(-1)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, dataloader):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        image, label, coord = batch\n",
    "        #print(image.size())\n",
    "        #print(label)\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            coord = coord.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        reconstruction, mu, log_var, z = model(image, label, coord)\n",
    "        \n",
    "        #print(reconstruction.shape)\n",
    "        \n",
    "        #image = image.to(torch.device('cpu'))\n",
    "        recon_loss = gaussian_likelihood(reconstruction, log_scale, image)\n",
    "        \n",
    "        std = torch.exp(log_var / 2)\n",
    "        kl = kl_divergence(z, mu, std)\n",
    "\n",
    "        elbo = ( kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "        \n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += elbo\n",
    "    \n",
    "    train_loss = running_loss/len(dataloader.dataset) #Investigate\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            \n",
    "            image, label, coord = batch\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                coord = coord.to(device)\n",
    "                \n",
    "            reconstruction, mu, log_var, z = model(image, label, coord)\n",
    "            \n",
    "            if (i == int(len(val_data)/dataloader.batch_size) - 1 and ( ((epoch%val_img_out_freq))==4) ): # or epoch > 90\n",
    "                num_rows = 4\n",
    "                both = torch.cat((image.view(batch_size, 3, image_size, image_size)[:4], \n",
    "                                  reconstruction.view(batch_size, 3, image_size, image_size)[:4]))\n",
    "                save_image(both.cpu(), f\"outputs/{parameter}{value}/imgs/output{epoch}.png\", nrow=num_rows)\n",
    "            \n",
    "            recon_loss = gaussian_likelihood(reconstruction, log_scale, image)\n",
    "            \n",
    "            std = torch.exp(log_var / 2)\n",
    "            kl = kl_divergence(z, mu, std)\n",
    "\n",
    "            elbo = (kl - recon_loss)\n",
    "            elbo = elbo.mean()\n",
    "            \n",
    "            running_loss += elbo \n",
    "            \n",
    "            i+=1\n",
    "    \n",
    "    val_loss = running_loss/len(dataloader.dataset)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_vectors(model, dataloader):\n",
    "    model.eval()\n",
    "    latent = []\n",
    "    target = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            image, label, coord = batch\n",
    "            #if torch.cuda.is_available():\n",
    "            #    data = data.to(device)\n",
    "            mu, logvar = model.encoder(image.cuda(), label.cuda(), coord.cuda())\n",
    "            latent.extend(mu.cpu().detach().numpy())\n",
    "            target.extend(label.numpy())\n",
    "#         print(len(latent))\n",
    "#         print(latent)\n",
    "#         print(len(target))\n",
    "#         print(target)\n",
    "        return latent, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "def run_each():\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "        sleep(0.2)\n",
    "        train_epoch_loss = fit(model, train_loader)\n",
    "        val_epoch_loss = validate(model, val_loader, epoch)\n",
    "\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        val_loss.append(val_epoch_loss)\n",
    "\n",
    "#         print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "#         print(f\"Val Loss: {val_epoch_loss:.4f}\")\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def runall():\n",
    "    train_loss, val_loss = run_each()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(range(1,epochs+1), train_loss, label=\"Train Loss\")\n",
    "    plt.plot(range(1,epochs+1), val_loss, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    axes = plt.gca()\n",
    "    \n",
    "    latent, target = generate_latent_vectors(model, val_loader)\n",
    "    \n",
    "    with open('outputs/'+parameter+value+'/sample_latent_vectors'+parameter+value+'.csv','w', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([\"Latent\", \"Target\"])\n",
    "        \n",
    "        for i in range (0,len(latent)):\n",
    "            latent[i] = list(latent[i])\n",
    "            \n",
    "        wr.writerows(zip(latent, target))\n",
    "    \n",
    "    filepath = os.path.join(os.getcwd(), \"outputs\", parameter+str(value), parameter+str(value)+\".pth\")\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    \n",
    "    plt.savefig('outputs/'+parameter+value+'/loss'+parameter+value+'.png')\n",
    "    \n",
    "    with open('outputs/'+parameter+value+'/loss'+parameter+value+'.csv','w', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([\"Train loss\", \"Val loss\"])\n",
    "        \n",
    "        for i in range (0,len(train_loss)):\n",
    "            train_loss[i] = train_loss[i].item()\n",
    "        \n",
    "        for i in range (0,len(val_loss)):\n",
    "            val_loss[i] = val_loss[i].item()\n",
    "            \n",
    "        wr.writerows(zip(train_loss, val_loss))\n",
    "        \n",
    "    with open('outputs/lossCompare.csv', 'a+', newline='') as f:\n",
    "        wr = csv.writer(f)\n",
    "        wr.writerow([parameter, value ,train_loss[-1], val_loss[-1], \n",
    "                     enc_out_dim, \n",
    "                     latent_dim, \n",
    "                     epochs,\n",
    "                     batch_size, \n",
    "                     learning_rate, \n",
    "                     kernel_size, \n",
    "                     stride,\n",
    "                     padding, \n",
    "                     init_filters,\n",
    "                     dropout_pcent,\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "param_dict = {\n",
    "    \n",
    "    \"enc_out_dim\": 512,\n",
    "    \"latent_dim\": 128,\n",
    "    \"conv_out_size\": 4,\n",
    "    \n",
    "    \"epochs\" : 25,\n",
    "    \"batch_size\" : 8,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    \n",
    "    \"kernel_size\" : 5,\n",
    "    \"stride\" : 2,\n",
    "    \"padding\" : 2,\n",
    "    \n",
    "    \"init_filters\" : 128,\n",
    "    \n",
    "    \"dropout_pcent\": 0.0,\n",
    "    \"image_size\": 128,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 188/188 [00:06<00:00, 29.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 88.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 75/75 [00:00<00:00, 110.12it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_img_out_freq = 5\n",
    "parameter_list = ['Reboot_']\n",
    "value_list = [2]\n",
    "\n",
    "for parameter in parameter_list:\n",
    "    for value in value_list:\n",
    "        #Update the values to be updated and rerun the experiment\n",
    "        enc_out_dim = param_dict[\"enc_out_dim\"]\n",
    "        latent_dim = param_dict[\"latent_dim\"]\n",
    "        conv_out_size = param_dict[\"conv_out_size\"]\n",
    "\n",
    "        epochs = param_dict[\"epochs\"]\n",
    "        batch_size = param_dict[\"batch_size\"]\n",
    "        learning_rate = param_dict[\"learning_rate\"]\n",
    "\n",
    "        kernel_size = param_dict[\"kernel_size\"]\n",
    "        stride = param_dict[\"stride\"]\n",
    "        padding = param_dict[\"padding\"]\n",
    "        init_filters = param_dict[\"init_filters\"]\n",
    "        \n",
    "        dropout_pcent = param_dict[\"dropout_pcent\"]\n",
    "        image_size = param_dict[\"image_size\"]\n",
    "        \n",
    "        #Move batch_size to before so its trained on the same split?\n",
    "        set_used = 'datasets/SmallGrey'\n",
    "        train_data = ActiveVisionDataset(csv_file=set_used+'/TrainSet/rgbCSV.csv', root_dir=set_used+'/TrainSet/segImg/', transform = torchvision.transforms.ToTensor())\n",
    "        val_data = ActiveVisionDataset(csv_file=set_used+'/ValSet/rgbCSV.csv', root_dir= set_used+'/ValSet/segImg/', transform = torchvision.transforms.ToTensor())\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        img_size = len(train_data[0][0][0])\n",
    "        model = ConditionalVAE(latent_dim).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        log_scale = nn.Parameter(torch.Tensor([0.0])).to(device)\n",
    "        \n",
    "        \n",
    "        #Change the value to a string for later\n",
    "        value = str(value)\n",
    "        os.makedirs(\"outputs/\"+parameter+str(value), exist_ok=True)\n",
    "        os.makedirs(\"outputs/\"+parameter+str(value)+\"/imgs\", exist_ok=True)\n",
    "        \n",
    "        #Run the Test\n",
    "        runall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
